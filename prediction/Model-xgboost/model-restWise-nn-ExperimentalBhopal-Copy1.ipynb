{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3488f333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:32.704190Z",
     "start_time": "2023-03-13T21:56:30.756949Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from statistics import mean\n",
    "import pickle\n",
    "import statistics\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from xgboost import XGBRegressor\n",
    "from numpy import absolute\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03a22cbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:32.973621Z",
     "start_time": "2023-03-13T21:56:32.966415Z"
    }
   },
   "outputs": [],
   "source": [
    "city = 'Bhopal'\n",
    "month = 'July'\n",
    "PATH = f'./../../Item_wise_data/{city}/'\n",
    "# PATH = './../'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "500b335e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:35.648250Z",
     "start_time": "2023-03-13T21:56:33.419680Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185411/70406848.py:2: DtypeWarning: Columns (5,8,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(PATH+f'{month}.csv')\n"
     ]
    }
   ],
   "source": [
    "# exclude non baking items\n",
    "df = pd.read_csv(PATH+f'{month}.csv')\n",
    "df = df[pd.notna(df['Oven_Time'])]\n",
    "df = df.sort_values(by =['Kitchen_Display_Time', 'Location_Code', 'Order_Number'])\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec45c79b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:35.739476Z",
     "start_time": "2023-03-13T21:56:35.651624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156415, 29)\n",
      "(156415, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df = df.drop(['storedesc', 'city', 'Customer_Code', 'Customer_Name', 'Actual_Order_Date', 'Order_Status_Code', 'Order_Type_Code', 'Order_Saved', 'Order_Time', 'Driver_ID', 'Route_Time', 'Return_Time', 'Delayed_Order', 'Order_Taker_ID','Order_Taker_Shift', 'Closed_Order_Time', 'Customer_Address_Id', 'Original_Location_Code', 'Order_Id',], axis=1)\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be15fa7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:35.936883Z",
     "start_time": "2023-03-13T21:56:35.742000Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156415, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Code</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Order_Number</th>\n",
       "      <th>Driver_Shift</th>\n",
       "      <th>Kitchen_Display_Time</th>\n",
       "      <th>Oven_Time</th>\n",
       "      <th>Menu_Code</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Delivery_Time</th>\n",
       "      <th>prep_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92935</th>\n",
       "      <td>DPI66576</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-01 11:06:45.417</td>\n",
       "      <td>2022-07-01 11:07:26.867</td>\n",
       "      <td>PIZ0200</td>\n",
       "      <td>Corn n Cheese Paratha Pizza</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158804</th>\n",
       "      <td>DPI66154</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:06:53.140</td>\n",
       "      <td>2022-07-01 11:09:58.387</td>\n",
       "      <td>PIZ5106</td>\n",
       "      <td>Chicken Sausage</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:24:46.000</td>\n",
       "      <td>185.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33904</th>\n",
       "      <td>DPI66576</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-01 11:12:01.983</td>\n",
       "      <td>2022-07-01 11:13:30.210</td>\n",
       "      <td>PIZ0121</td>\n",
       "      <td>VG2-1Mexican Green</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:26:48.840</td>\n",
       "      <td>88.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69467</th>\n",
       "      <td>DPI66576</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-01 11:12:01.983</td>\n",
       "      <td>2022-07-01 11:13:30.697</td>\n",
       "      <td>PIZ0120</td>\n",
       "      <td>VG2-1Peppy Paneer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:26:48.840</td>\n",
       "      <td>88.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53156</th>\n",
       "      <td>DPI66449</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:12:33.490</td>\n",
       "      <td>2022-07-01 11:13:58.503</td>\n",
       "      <td>PIZ0130</td>\n",
       "      <td>_PM39-Pizza Mania Golden Corn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:32:00.000</td>\n",
       "      <td>85.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location_Code           Order_Date  Order_Number  Driver_Shift  \\\n",
       "92935       DPI66576  2022-07-01 00:00:00             1           0.0   \n",
       "158804      DPI66154  2022-07-01 00:00:00             1           1.0   \n",
       "33904       DPI66576  2022-07-01 00:00:00             2           0.0   \n",
       "69467       DPI66576  2022-07-01 00:00:00             2           0.0   \n",
       "53156       DPI66449  2022-07-01 00:00:00             2           1.0   \n",
       "\n",
       "          Kitchen_Display_Time               Oven_Time Menu_Code  \\\n",
       "92935  2022-07-01 11:06:45.417 2022-07-01 11:07:26.867   PIZ0200   \n",
       "158804 2022-07-01 11:06:53.140 2022-07-01 11:09:58.387   PIZ5106   \n",
       "33904  2022-07-01 11:12:01.983 2022-07-01 11:13:30.210   PIZ0121   \n",
       "69467  2022-07-01 11:12:01.983 2022-07-01 11:13:30.697   PIZ0120   \n",
       "53156  2022-07-01 11:12:33.490 2022-07-01 11:13:58.503   PIZ0130   \n",
       "\n",
       "                     Item Description  Quantity            Delivery_Time  \\\n",
       "92935     Corn n Cheese Paratha Pizza       1.0                      NaN   \n",
       "158804                Chicken Sausage       1.0  2022-07-01 11:24:46.000   \n",
       "33904              VG2-1Mexican Green       1.0  2022-07-01 11:26:48.840   \n",
       "69467               VG2-1Peppy Paneer       1.0  2022-07-01 11:26:48.840   \n",
       "53156   _PM39-Pizza Mania Golden Corn       1.0  2022-07-01 11:32:00.000   \n",
       "\n",
       "        prep_time  \n",
       "92935      41.450  \n",
       "158804    185.247  \n",
       "33904      88.227  \n",
       "69467      88.714  \n",
       "53156      85.013  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Kitchen_Display_Time'] = pd.to_datetime(df['Kitchen_Display_Time'])\n",
    "df['Oven_Time'] = pd.to_datetime(df['Oven_Time'])\n",
    "df['prep_time'] = df['Oven_Time'] - df['Kitchen_Display_Time']\n",
    "df['prep_time'] = (df['prep_time']/np.timedelta64(1, 's')).astype(float)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b36a4fbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:36.271268Z",
     "start_time": "2023-03-13T21:56:36.044733Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156186, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Code</th>\n",
       "      <th>Order_Date</th>\n",
       "      <th>Order_Number</th>\n",
       "      <th>Driver_Shift</th>\n",
       "      <th>Kitchen_Display_Time</th>\n",
       "      <th>Oven_Time</th>\n",
       "      <th>Menu_Code</th>\n",
       "      <th>Item Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Delivery_Time</th>\n",
       "      <th>prep_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92935</th>\n",
       "      <td>DPI66576</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-01 11:06:45.417</td>\n",
       "      <td>2022-07-01 11:07:26.867</td>\n",
       "      <td>PIZ0200</td>\n",
       "      <td>Corn n Cheese Paratha Pizza</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158804</th>\n",
       "      <td>DPI66154</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:06:53.140</td>\n",
       "      <td>2022-07-01 11:09:58.387</td>\n",
       "      <td>PIZ5106</td>\n",
       "      <td>Chicken Sausage</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:24:46.000</td>\n",
       "      <td>185.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33904</th>\n",
       "      <td>DPI66576</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-01 11:12:01.983</td>\n",
       "      <td>2022-07-01 11:13:30.210</td>\n",
       "      <td>PIZ0121</td>\n",
       "      <td>VG2-1Mexican Green</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:26:48.840</td>\n",
       "      <td>88.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69467</th>\n",
       "      <td>DPI66576</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2022-07-01 11:12:01.983</td>\n",
       "      <td>2022-07-01 11:13:30.697</td>\n",
       "      <td>PIZ0120</td>\n",
       "      <td>VG2-1Peppy Paneer</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:26:48.840</td>\n",
       "      <td>88.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53156</th>\n",
       "      <td>DPI66449</td>\n",
       "      <td>2022-07-01 00:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:12:33.490</td>\n",
       "      <td>2022-07-01 11:13:58.503</td>\n",
       "      <td>PIZ0130</td>\n",
       "      <td>_PM39-Pizza Mania Golden Corn</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2022-07-01 11:32:00.000</td>\n",
       "      <td>85.013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Location_Code           Order_Date  Order_Number  Driver_Shift  \\\n",
       "92935       DPI66576  2022-07-01 00:00:00             1           0.0   \n",
       "158804      DPI66154  2022-07-01 00:00:00             1           1.0   \n",
       "33904       DPI66576  2022-07-01 00:00:00             2           0.0   \n",
       "69467       DPI66576  2022-07-01 00:00:00             2           0.0   \n",
       "53156       DPI66449  2022-07-01 00:00:00             2           1.0   \n",
       "\n",
       "          Kitchen_Display_Time               Oven_Time Menu_Code  \\\n",
       "92935  2022-07-01 11:06:45.417 2022-07-01 11:07:26.867   PIZ0200   \n",
       "158804 2022-07-01 11:06:53.140 2022-07-01 11:09:58.387   PIZ5106   \n",
       "33904  2022-07-01 11:12:01.983 2022-07-01 11:13:30.210   PIZ0121   \n",
       "69467  2022-07-01 11:12:01.983 2022-07-01 11:13:30.697   PIZ0120   \n",
       "53156  2022-07-01 11:12:33.490 2022-07-01 11:13:58.503   PIZ0130   \n",
       "\n",
       "                     Item Description  Quantity            Delivery_Time  \\\n",
       "92935     Corn n Cheese Paratha Pizza       1.0                      NaN   \n",
       "158804                Chicken Sausage       1.0  2022-07-01 11:24:46.000   \n",
       "33904              VG2-1Mexican Green       1.0  2022-07-01 11:26:48.840   \n",
       "69467               VG2-1Peppy Paneer       1.0  2022-07-01 11:26:48.840   \n",
       "53156   _PM39-Pizza Mania Golden Corn       1.0  2022-07-01 11:32:00.000   \n",
       "\n",
       "        prep_time  \n",
       "92935      41.450  \n",
       "158804    185.247  \n",
       "33904      88.227  \n",
       "69467      88.714  \n",
       "53156      85.013  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isThresholdForPreparationTime = True\n",
    "thresholdForPreparationTimeUpper = 15 # minutes for preparation time (threshold)\n",
    "thresholdForPreparationTimeLower = 0 # minutes for lowest preparation time (threshold)\n",
    "df2 = pd.DataFrame()\n",
    "if (isThresholdForPreparationTime):\n",
    "    df = df.loc[(df['prep_time'] <= thresholdForPreparationTimeUpper*60) & \\\n",
    "        (df['prep_time'] >= thresholdForPreparationTimeLower*60) ]\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4877e791",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:36.981807Z",
     "start_time": "2023-03-13T21:56:36.947458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "allMenuCodes = df['Menu_Code'].unique()\n",
    "allStoreIds = df['Location_Code'].unique()\n",
    "# allMenuCodes,\n",
    "# allStoreIds\n",
    "print(len(allMenuCodes))\n",
    "print(len(allStoreIds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd82fb15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:37.459730Z",
     "start_time": "2023-03-13T21:56:37.316409Z"
    }
   },
   "outputs": [],
   "source": [
    "restWiseDFs = {}\n",
    "for storeId in allStoreIds:\n",
    "    restWiseDFs[storeId] = df.loc[df['Location_Code'] == storeId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a83c42a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:37.846850Z",
     "start_time": "2023-03-13T21:56:37.840785Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_preparation_time(item):\n",
    "    return item['prep_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3259a2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:38.805639Z",
     "start_time": "2023-03-13T21:56:38.200139Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleItem=None\n",
    "for index, item in df.iterrows():\n",
    "    sampleItem = item\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ed902e2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:38.816297Z",
     "start_time": "2023-03-13T21:56:38.809512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 1: store id\n",
    "def getOneHotEncodingStore(storeId, stores=allStoreIds):\n",
    "    oneHotEncodingList = []\n",
    "    for i in range(0, len(stores)):\n",
    "        if stores[i] == storeId:\n",
    "            oneHotEncodingList.append(1)\n",
    "        else:\n",
    "            oneHotEncodingList.append(0)\n",
    "    return oneHotEncodingList\n",
    "\n",
    "# returns the feature store id for an order\n",
    "def getStoreId(item, isOneHotEncodingRequired=False):\n",
    "    if isOneHotEncodingRequired:\n",
    "        return getOneHotEncodingStore(item['Location_Code'], allStoreIds)\n",
    "    else:\n",
    "        for i in range(0, len(allStoreIds)):\n",
    "            if item['Location_Code'] == allStoreIds[i]:\n",
    "                return [i+1]\n",
    "        return [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bd329c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:38.996795Z",
     "start_time": "2023-03-13T21:56:38.988217Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 2 : Day of the week\n",
    "def dayOfTheWeek(dt, isOneHotEncodingRequired=False):\n",
    "    day = dt.weekday()\n",
    "    if isOneHotEncodingRequired:\n",
    "        days = [0, 0, 0, 0, 0, 0, 0]\n",
    "        days[day] = 1\n",
    "        return days\n",
    "    else:\n",
    "        return [day+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "517c95d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:39.375741Z",
     "start_time": "2023-03-13T21:56:39.368436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(getStoreId(sampleItem))\n",
    "print(getStoreId(sampleItem, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d7aca59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:39.843964Z",
     "start_time": "2023-03-13T21:56:39.831857Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 3: TimeSlot of kitchen display time\n",
    "total_slots = 24\n",
    "def getTimeslot(dt, slots=total_slots):\n",
    "\tcurrent = datetime(2011, 1, 1)\n",
    "\tt1 = current.time()\n",
    "\tt2 = dt.time()\n",
    "\tfor i in range(0, slots):\n",
    "\t\tcurrent = current + timedelta(minutes = 60*24/slots)\n",
    "\t\tif(current.time() > t2):\n",
    "\t\t\treturn i\n",
    "\treturn slots-1\n",
    "\n",
    "def getOneHotEncodingTimeSlot(timeslot):\n",
    "    oneHotEncodingList = []\n",
    "    for i in range(0, 24):\n",
    "        oneHotEncodingList.append(0)\n",
    "    oneHotEncodingList[timeslot] = 1\n",
    "    return oneHotEncodingList\n",
    "\n",
    "def getTimeSlotOfKitchenDisplayTime(item, isOneHotEncodingRequired=False):\n",
    "    timeslot = getTimeslot(item['Kitchen_Display_Time'], 24)\n",
    "    if (isOneHotEncodingRequired):\n",
    "        return getOneHotEncodingTimeSlot(timeslot)\n",
    "    else:\n",
    "        return [1+timeslot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73180e66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:40.521084Z",
     "start_time": "2023-03-13T21:56:40.507670Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 4: Item Type\n",
    "def getOneHotEncodedItemList(item, items=allMenuCodes, clubCategoryWise=False):\n",
    "    if clubCategoryWise:\n",
    "        newItemsList = []\n",
    "        newItemsList = [i[0:3] for i in items]\n",
    "        unique_items = list(dict.fromkeys(newItemsList))\n",
    "        return getOneHotEncodedItemList(item[0:3], unique_items, False)\n",
    "    \n",
    "    oneHotEncodingList=[]\n",
    "    for i in range(0, len(items)):\n",
    "        if items[i] == item:\n",
    "            oneHotEncodingList.append(1)\n",
    "        else:\n",
    "            oneHotEncodingList.append(0)\n",
    "    return oneHotEncodingList\n",
    "\n",
    "def getItemType(item, clubCategoryWise=False, isOneHotEncodingRequired=False):\n",
    "    if isOneHotEncodingRequired:\n",
    "        return getOneHotEncodedItemList(item['Menu_Code'], allMenuCodes, clubCategoryWise)\n",
    "    else:\n",
    "        for i in range(0, len(allMenuCodes)):\n",
    "            if allMenuCodes[i] == item['Menu_Code']:\n",
    "                return [i+1]\n",
    "        print(\"DANGER DANGER DANGER \\n\\n\\n\")\n",
    "        return [-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "042b3f08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:41.118549Z",
     "start_time": "2023-03-13T21:56:41.109575Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1]\n",
      "[1]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(getItemType(sampleItem, False, True))\n",
    "print(getItemType(sampleItem, True, False))\n",
    "print(getItemType(sampleItem, clubCategoryWise=True))\n",
    "print(getItemType(sampleItem, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98906d7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:41.709070Z",
     "start_time": "2023-03-13T21:56:41.700275Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 5 : Count of all baking items of all orders received by the store in the last 30 minutes.\n",
    "\n",
    "def countPastOrders(item, slotTime=30):\n",
    "    storeId = item['Location_Code']\n",
    "    df = restWiseDFs[storeId]\n",
    "    dtKitchenDisplay = item['Kitchen_Display_Time']\n",
    "    lastTime = dtKitchenDisplay - timedelta(minutes=slotTime)\n",
    "    return len(df.loc[(df['Kitchen_Display_Time'] >= lastTime) & \\\n",
    "          (df['Kitchen_Display_Time'] <= dtKitchenDisplay)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7a72af53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T21:56:42.297357Z",
     "start_time": "2023-03-13T21:56:42.289057Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 6: ratio of items in last 30 minutes with items in the window of last 60 to 30 minutes (increment in orders)\n",
    "def getLiftInOrders(item, slotTime = 30):\n",
    "    a = countPastOrders(item, slotTime)\n",
    "    item2 = item\n",
    "    item2['Kitchen_Display_Time'] = item2['Kitchen_Display_Time'] - timedelta(minutes=slotTime)\n",
    "    b = countPastOrders(item2, slotTime)\n",
    "    if b != 0:\n",
    "        return a/b\n",
    "    else:\n",
    "        return 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "13d55221",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:08.225649Z",
     "start_time": "2023-03-13T21:56:43.375412Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
      "/tmp/ipykernel_185411/341973426.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
      "/tmp/ipykernel_185411/341973426.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n"
     ]
    }
   ],
   "source": [
    "# TIME CONSUMING (4 m 14 seconds for Bhopal)\n",
    "# Feature 7 : Avg prep time of the same item in the same store in last 60 minutes.\n",
    "# Feature 8 : Avg prep time of the same item in the same store in last 7 days.\n",
    "for storeId in restWiseDFs:\n",
    "    avgPrepTime = restWiseDFs[storeId]['prep_time'].mean()    \n",
    "    restWiseDFs[storeId]['avg_kpt_in_last_one_hour'] = 0 # to create a new column with initial values 0\n",
    "    restWiseDFs[storeId]['avg_kpt_in_last_7_days'] = 0\n",
    "    restWiseDFs[storeId]['hourswise_avg_kpt'] = 0\n",
    "    for index, item in restWiseDFs[storeId].iterrows():\n",
    "        itemCode = item['Menu_Code']\n",
    "        dtKitchenDisplay = item['Kitchen_Display_Time']\n",
    "        lastTimeMinutes = dtKitchenDisplay - timedelta(minutes=60)\n",
    "        lastTime = dtKitchenDisplay - timedelta(days=7)\n",
    "        df3 = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= lastTime) & \\\n",
    "                     (restWiseDFs[storeId]['Kitchen_Display_Time'] < dtKitchenDisplay) & \\\n",
    "                                 (restWiseDFs[storeId]['Menu_Code'] == itemCode)]\n",
    "        df2 = df3.loc[df3['Kitchen_Display_Time'] >= lastTimeMinutes]\n",
    "        if len(df3.index) != 0:\n",
    "            restWiseDFs[storeId].at[index, 'avg_kpt_in_last_one_hour'] = df2['prep_time'].mean()\n",
    "        else:\n",
    "            restWiseDFs[storeId].at[index, 'avg_kpt_in_last_one_hour'] =  avgPrepTime\n",
    "        if len(df2.index) != 0:\n",
    "            restWiseDFs[storeId].at[index, 'avg_kpt_in_last_7_days'] = df3['prep_time'].mean()\n",
    "        else:\n",
    "            restWiseDFs[storeId].at[index, 'avg_kpt_in_last_7_days'] =  avgPrepTime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5d71b1bf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:08.236807Z",
     "start_time": "2023-03-13T22:02:08.229741Z"
    }
   },
   "outputs": [],
   "source": [
    "def getPreviousPrepTime(item, timeslot = 60):\n",
    "    if timeslot == 60:\n",
    "        return item['avg_kpt_in_last_one_hour']\n",
    "    elif timeslot == 7*24*60:\n",
    "        return item['avg_kpt_in_last_7_days']\n",
    "    else:\n",
    "        itemCode = item['Menu_Code']\n",
    "        df = restWiseDFs[item['Location_Code']]\n",
    "\n",
    "        dtKitchenDisplay = item['Kitchen_Display_Time']\n",
    "\n",
    "        lastTime = dtKitchenDisplay - timedelta(minutes=timeslot)\n",
    "\n",
    "        df2 = df.loc[(df['Kitchen_Display_Time'] >= lastTime) & \\\n",
    "                     (df['Kitchen_Display_Time'] < dtKitchenDisplay) & \\\n",
    "                                 (df['Menu_Code'] == itemCode)]\n",
    "        if len(df2.index) != 0:\n",
    "            return df2['prep_time'].mean()\n",
    "        else:\n",
    "            return restWiseDFs[storeId]['prep_time'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4abbd28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:18.957412Z",
     "start_time": "2023-03-13T22:02:08.238978Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n",
      "/tmp/ipykernel_185411/2358782154.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa\n"
     ]
    }
   ],
   "source": [
    "# Hourwise avg\n",
    "# Feature 9 : Avg prep time of the same item in same store : hour wise + according to the day of the week\n",
    "hourWiseAvg = {}\n",
    "for store in allStoreIds:\n",
    "    hourWiseAvg[store] = {}\n",
    "    for i in range(1, 8):\n",
    "        hourWiseAvg[store][i] = {}\n",
    "\n",
    "for storeId in allStoreIds:\n",
    "    hwa = []\n",
    "    for index, item in restWiseDFs[storeId].iterrows():\n",
    "        ts = getTimeslot(item['Kitchen_Display_Time'])\n",
    "        d = dayOfTheWeek(item['Kitchen_Display_Time'])[0]\n",
    "        if ts not in hourWiseAvg[storeId][d]:\n",
    "            hourWiseAvg[storeId][d][ts] = {'val': 0, 'cnt': 0}\n",
    "        if hourWiseAvg[storeId][d][ts]['cnt'] == 0:\n",
    "            hwa.append(item['avg_kpt_in_last_one_hour'])\n",
    "        else:\n",
    "            hwa.append(hourWiseAvg[storeId][d][ts]['val']/hourWiseAvg[storeId][d][ts]['cnt'])\n",
    "        hourWiseAvg[storeId][d][ts]['val'] += item['prep_time']\n",
    "        hourWiseAvg[storeId][d][ts]['cnt'] += 1\n",
    "\n",
    "    restWiseDFs[storeId]['hour_wise_avg_kpt_of_the_day'] = hwa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26414d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:18.964792Z",
     "start_time": "2023-03-13T22:02:18.960575Z"
    }
   },
   "outputs": [],
   "source": [
    "def getHourWiseAverage(item):\n",
    "    return item[\"hour_wise_avg_kpt_of_the_day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b7a13443",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:18.975258Z",
     "start_time": "2023-03-13T22:02:18.966666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 10 : Item quantity\n",
    "def getQuantity(item):\n",
    "    return item['Quantity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6c90edd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:18.982898Z",
     "start_time": "2023-03-13T22:02:18.977265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Feature 11 : Length of the queue in the store at that time\n",
    "def lengthQueue(item):\n",
    "    dtKitchenDisplay = item['Kitchen_Display_Time']\n",
    "    d = restWiseDFs[item['Location_Code']]\n",
    "    return len(d[(d['Oven_Time'] >= dtKitchenDisplay) & (d['Kitchen_Display_Time'] <= dtKitchenDisplay)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d7f459b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:19.047829Z",
     "start_time": "2023-03-13T22:02:18.984724Z"
    }
   },
   "outputs": [],
   "source": [
    "sampleItem=None\n",
    "for index, item in restWiseDFs[storeId].iterrows():\n",
    "    sampleItem = item\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e34eb51d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:19.056945Z",
     "start_time": "2023-03-13T22:02:19.050060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengthQueue(sampleItem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7b85e23b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:19.860749Z",
     "start_time": "2023-03-13T22:02:19.345413Z"
    }
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "\n",
    "clubItemsCategoryWise = False\n",
    "\n",
    "splitMethod = 'initial 21 days'\n",
    "slotTimeForPastOrders = 30 # minutes\n",
    "\n",
    "model = 'xgboost'\n",
    "isOneHotEncodingRequired = False\n",
    "isNormalizationRequired = True\n",
    "\n",
    "isCentralModel = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "636ecf24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:19.878517Z",
     "start_time": "2023-03-13T22:02:19.866382Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_object(obj, filename):\n",
    "    with open(filename, 'wb') as outp:  # Overwrites any existing file.\n",
    "        pickle.dump(obj, outp, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d513b5e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:19.994944Z",
     "start_time": "2023-03-13T22:02:19.883806Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(restWiseDFs, f'restWiseDFsBeforeFeatureCreation{city}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ecd2d076",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:20.003396Z",
     "start_time": "2023-03-13T22:02:19.997200Z"
    }
   },
   "outputs": [],
   "source": [
    "totalFeatures = (0 + # store ID (categorical)\n",
    "                1 + # day of the week (categorical)\n",
    "                1 +  #timeslot of the day (categorical)\n",
    "                1 +  # Item type (categorical)\n",
    "                1 +  #count past orders in last 30 minutes\n",
    "                1 +  #ratio lift in last 30 minutes\n",
    "                1 + # average previous preparation time in last 1 hour\n",
    "                1 + # average previous preparation time in last 7 days\n",
    "                1 + # average kpt time, hour wise according to the day of the week\n",
    "                1 + # Item quantity\n",
    "                1) # length of the current queue\n",
    "\n",
    "if isCentralModel:\n",
    "    totalFeatures += 1\n",
    "if isOneHotEncodingRequired:\n",
    "    ##### DEPRECATED\n",
    "    totalFeatures = (7 + # one hot encoded day of the week\n",
    "                 len(allMenuCodes) +  # Item type\n",
    "                24 +  #timeslot of the day\n",
    "                1 +  #count past orders\n",
    "                1 +  #lift in last 30 minutes\n",
    "                1 + # average previous preparation time in last 1 hour\n",
    "                1 + # average previous preparation time in last 7 days\n",
    "                1) # length of the current queue\n",
    "    if isCentralModel:\n",
    "        totalFeatures += len(allStoreIds)\n",
    "\n",
    "feature_cols = []\n",
    "for i in range(0, totalFeatures):\n",
    "    feature_cols.append('feature_'+str(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d558b02e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:02:20.069799Z",
     "start_time": "2023-03-13T22:02:20.005255Z"
    }
   },
   "outputs": [],
   "source": [
    "def updateFeatures(storeId, Xnp):\n",
    "    restWiseDFs[storeId][feature_cols] = Xnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e135b945",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-13T22:08:18.562377Z",
     "start_time": "2023-03-13T22:02:20.074077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16460, 11)\n",
      "(10763, 11)\n",
      "(18798, 11)\n",
      "(14284, 11)\n",
      "(11443, 11)\n",
      "(12344, 11)\n",
      "(17184, 11)\n",
      "(9330, 11)\n",
      "(10509, 11)\n",
      "(12105, 11)\n",
      "(12230, 11)\n",
      "(10736, 11)\n"
     ]
    }
   ],
   "source": [
    "# TIME CONSUMING (3m 21s for Bhopal)\n",
    "for storeId in restWiseDFs:\n",
    "    X = []\n",
    "    df = restWiseDFs[storeId]\n",
    "    for index, item in df.iterrows():\n",
    "        features = getStoreId(item, False)\n",
    "        features += dayOfTheWeek(item['Kitchen_Display_Time'], isOneHotEncodingRequired)\n",
    "        features += getTimeSlotOfKitchenDisplayTime(item, isOneHotEncodingRequired)\n",
    "        features += getItemType(item, clubItemsCategoryWise, isOneHotEncodingRequired)\n",
    "        features += [countPastOrders(item, slotTimeForPastOrders)]\n",
    "        features += [getLiftInOrders(item, slotTimeForPastOrders)]\n",
    "        features += [getPreviousPrepTime(item, timeslot = 60)]\n",
    "        features += [getPreviousPrepTime(item, timeslot = 7*24*60)]\n",
    "        features += [getHourWiseAverage(item)]\n",
    "        features += [getQuantity(item)]\n",
    "        features += [lengthQueue(item)]\n",
    "        X.append(features)\n",
    "    Xnp = np.array(X)\n",
    "    updateFeatures(storeId, Xnp)\n",
    "    print(Xnp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8a299038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T07:00:09.582720Z",
     "start_time": "2023-03-10T07:00:09.471103Z"
    }
   },
   "outputs": [],
   "source": [
    "# categorical data\n",
    "if not isOneHotEncodingRequired:\n",
    "    for i in range(0, 4):\n",
    "        for storeId in allStoreIds:\n",
    "            restWiseDFs[storeId][feature_cols[i]] = restWiseDFs[storeId][feature_cols[i]].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef377b61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T07:00:09.589073Z",
     "start_time": "2023-03-10T07:00:09.584594Z"
    }
   },
   "outputs": [],
   "source": [
    "restWiseScalers = {}\n",
    "\n",
    "# normalize feature values\n",
    "if isNormalizationRequired:\n",
    "    for storeId in allStoreIds:\n",
    "        firstTime = datetime(2022, 7, 1)\n",
    "        lastTime = datetime(2022, 7, 21)\n",
    "        trainingData = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "              (restWiseDFs[storeId]['Kitchen_Display_Time'] <= lastTime)].loc[:, feature_cols]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(trainingData)\n",
    "        if isNormalizationRequired:\n",
    "            X = restWiseDFs[storeId].loc[:, feature_cols]\n",
    "            X_scaled = scaler.transform(X)\n",
    "            X_scalednp = np.array(X_scaled)\n",
    "            updateFeatures(storeId, X_scalednp)\n",
    "    save_object(restWiseDFs, f'restWiseDFsWithNormalizedFeatures{city}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4d647b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T07:00:09.602387Z",
     "start_time": "2023-03-10T07:00:09.590733Z"
    }
   },
   "outputs": [],
   "source": [
    "def getRMSE(actual, predictions):\n",
    "    mse = sklearn.metrics.mean_squared_error(actual, predictions)\n",
    "    return math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "068f2211",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.054722Z",
     "start_time": "2023-03-10T07:00:09.604162Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'colsample_bytree': 0.8, 'enable_categorical': True, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50, 'subsample': 0.9, 'tree_method': 'hist'}\n",
      "Best mean cross-validated score: 0.3040978583483841\n",
      "Test score: 0.1999871906856454\n"
     ]
    },
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11'])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/dominos/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/dominos/lib/python3.10/site-packages/pandas/_libs/index.pyx:138\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/dominos/lib/python3.10/site-packages/pandas/_libs/index.pyx:144\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: '(slice(None, None, None), ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11'])' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 61\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, test_score)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;66;03m# regressor.fit(X_train, y_train)\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# restWiseModelsXGB[storeId] = best_regressor\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m overallPredictions \u001b[38;5;241m=\u001b[39m best_regressor\u001b[38;5;241m.\u001b[39mpredict(\u001b[43moverallDF\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     62\u001b[0m overallDF[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_prep_time_central\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m overallPredictions\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mACCURACY ON TRAINING DATA : \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/dominos/lib/python3.10/site-packages/pandas/core/frame.py:3807\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   3806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3807\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3808\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3809\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/dominos/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3805\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3807\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m-> 3809\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3810\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[0;32m~/dominos/lib/python3.10/site-packages/pandas/core/indexes/base.py:5925\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   5921\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   5922\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[1;32m   5923\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[1;32m   5924\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[0;32m-> 5925\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[0;31mInvalidIndexError\u001b[0m: (slice(None, None, None), ['feature_1', 'feature_2', 'feature_3', 'feature_4', 'feature_5', 'feature_6', 'feature_7', 'feature_8', 'feature_9', 'feature_10', 'feature_11'])"
     ]
    }
   ],
   "source": [
    "if isCentralModel:\n",
    "    overallDF = pd.DataFrame()\n",
    "    for storeId in allStoreIds:\n",
    "        overallDF = pd.concat([overallDF, restWiseDFs[storeId]], ignore_index=True)\n",
    "    firstTime = datetime(2022, 7, 1)\n",
    "    lastTime = datetime(2022, 7, 21) + timedelta(days=1)\n",
    "    trainingData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (overallDF['Kitchen_Display_Time'] < lastTime)]\n",
    "    X_train = trainingData.loc[:, feature_cols]\n",
    "    y_train = trainingData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 22)\n",
    "    lastTime = datetime(2022, 7, 23) + timedelta(days=1)\n",
    "    validationData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_train_val = validationData.loc[:, feature_cols]\n",
    "    y_train_val = validationData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 24)\n",
    "    lastTime = datetime(2022, 7, 31) + timedelta(days=1)\n",
    "    testData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_test = testData.loc[:, feature_cols]\n",
    "    y_test = testData.prep_time.values.tolist()\n",
    "\n",
    "\n",
    "    regressor = XGBRegressor()\n",
    "    param_grid = {\n",
    "        'tree_method': ['approx', 'hist'],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10, 12, 14],\n",
    "        'learning_rate': [0.2, 0.1, 0.01],\n",
    "        'subsample': [0.7, 0.8, 0.9],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "        'enable_categorical': [True],\n",
    "    }\n",
    "\n",
    "    # define the GridSearchCV object with the parameter grid and the XGBRegressor model\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5)\n",
    "\n",
    "    # fit the GridSearchCV object on the training set\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # print the best hyperparameters and the corresponding mean cross-validated score\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best mean cross-validated score:\", grid_search.best_score_)\n",
    "\n",
    "    # retrain the model on the combined training and validation sets with the best hyperparameters\n",
    "    best_regressor = XGBRegressor(**grid_search.best_params_)\n",
    "    best_regressor.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # evaluate the final model performance on the test set\n",
    "    test_score = best_regressor.score(X_test, y_test)\n",
    "    print(\"Test score:\", test_score)\n",
    "\n",
    "    # regressor.fit(X_train, y_train)\n",
    "    # restWiseModelsXGB[storeId] = best_regressor\n",
    "\n",
    "    overallPredictions = best_regressor.predict(overallDF[:, feature_cols])\n",
    "    overallDF['predicted_prep_time_central'] = overallPredictions\n",
    "\n",
    "\n",
    "    print(\"ACCURACY ON TRAINING DATA : \")\n",
    "\n",
    "    for storeId in allStoreIds:\n",
    "        restWiseDFs[storeId] = overallDF.loc[overallDF['Location_Code'] == storeId]\n",
    "        X = restWiseDFs[storeId].loc[:, feature_cols]\n",
    "        y = restWiseDFs[storeId].prep_time.values.tolist()\n",
    "        predictions = restWiseDFs[storeId]['predicted_prep_time_central']\n",
    "        print(\"RMSE score overall for store central model (30 days) \"+storeId+\" :  \", getRMSE(y, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35642320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0886f05b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.060249Z",
     "start_time": "2023-03-10T10:34:07.060234Z"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "f = ['storeId', 'dayOfTheWeek', 'Timeslot', 'ItemType', 'countPastOrders', 'ratioOfCountOrders', 'prevAvgKPT60Minutes', 'prepAvgKPT7Days', 'hourDayWiseAvgKPT', 'Quantity', 'QueueLenght']\n",
    "pyplot.bar(f, best_regressor.feature_importances_)\n",
    "pyplot.xticks(rotation=90)\n",
    "pyplot.title(\"Feature Importance\")\n",
    "pyplot.show()\n",
    "print(sum(best_regressor.feature_importances_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3be2c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.061607Z",
     "start_time": "2023-03-10T10:34:07.061593Z"
    }
   },
   "outputs": [],
   "source": [
    "# Experiment 1\n",
    "# remove feature with feature value less than 0.05\n",
    "# Remaining Features : 1,2,3,5,7,8,9\n",
    "totalFeatures = (1 +  # store ID (categorical)\n",
    "                 1 +  # day of the week (categorical)\n",
    "                 1 +  #timeslot of the day (categorical)\n",
    "                 1 +  #count past orders in last 30 minutes\n",
    "                 1 +  # average previous preparation time in last 1 hour\n",
    "                 1 +  # average previous preparation time in last 7 days\n",
    "                 1  # average kpt time, hour wise according to the day of the week\n",
    "                 )  # length of the current queue\n",
    "\n",
    "feature_cols = []\n",
    "for i in range(0, totalFeatures):\n",
    "    feature_cols.append('feature_' + str(i + 1))\n",
    "# TIME CONSUMING (3m 21s for Bhopal)\n",
    "for storeId in restWiseDFs:\n",
    "    X = []\n",
    "    df = restWiseDFs[storeId]\n",
    "    for index, item in df.iterrows():\n",
    "        features = getStoreId(item, False)\n",
    "        features += dayOfTheWeek(item['Kitchen_Display_Time'], isOneHotEncodingRequired)\n",
    "        features += getTimeSlotOfKitchenDisplayTime(item, isOneHotEncodingRequired)\n",
    "        # features += getItemType(item, clubItemsCategoryWise, isOneHotEncodingRequired)\n",
    "        features += [countPastOrders(item, slotTimeForPastOrders)]\n",
    "        # features += [getLiftInOrders(item, slotTimeForPastOrders)]\n",
    "        features += [getPreviousPrepTime(item, timeslot=60)]\n",
    "        features += [getPreviousPrepTime(item, timeslot=7 * 24 * 60)]\n",
    "        features += [getHourWiseAverage(item)]\n",
    "        # features += [getQuantity(item)]\n",
    "        # features += [lengthQueue(item)]\n",
    "        X.append(features)\n",
    "    Xnp = np.array(X)\n",
    "    updateFeatures(storeId, Xnp)\n",
    "    print(Xnp.shape)\n",
    "# categorical data\n",
    "if not isOneHotEncodingRequired:\n",
    "    for i in range(0, 4):\n",
    "        for storeId in allStoreIds:\n",
    "            restWiseDFs[storeId][feature_cols[i]] = restWiseDFs[storeId][feature_cols[i]].astype(\"category\")\n",
    "restWiseScalers = {}\n",
    "\n",
    "# normalize feature values\n",
    "if isNormalizationRequired:\n",
    "    for storeId in allStoreIds:\n",
    "        firstTime = datetime(2022, 7, 1)\n",
    "        lastTime = datetime(2022, 7, 14)\n",
    "        trainingData = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "                                                (restWiseDFs[storeId]['Kitchen_Display_Time'] <= lastTime)].loc[:,\n",
    "                       feature_cols]\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(trainingData)\n",
    "        if isNormalizationRequired:\n",
    "            X = restWiseDFs[storeId].loc[:, feature_cols]\n",
    "            X_scaled = scaler.transform(X)\n",
    "            X_scalednp = np.array(X_scaled)\n",
    "            updateFeatures(storeId, X_scalednp)\n",
    "    save_object(restWiseDFs, f'restWiseDFsWithNormalizedFeatures{city}.pkl')\n",
    "\n",
    "\n",
    "if isCentralModel:\n",
    "    overallDF = pd.DataFrame()\n",
    "    for storeId in allStoreIds:\n",
    "        overallDF = pd.concat([overallDF, restWiseDFs[storeId]], ignore_index=True)\n",
    "    firstTime = datetime(2022, 7, 1)\n",
    "    lastTime = datetime(2022, 7, 14)\n",
    "    trainingData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "                                 (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "    X_train = trainingData.loc[:, feature_cols]\n",
    "    y_train = trainingData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 15)\n",
    "    lastTime = datetime(2022, 7, 21)\n",
    "    validationData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "                                   (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_train_val = validationData.loc[:, feature_cols]\n",
    "    y_train_val = validationData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 22)\n",
    "    lastTime = datetime(2022, 7, 31)\n",
    "    testData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "                             (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_test = testData.loc[:, feature_cols]\n",
    "    y_test = testData.prep_time.values.tolist()\n",
    "\n",
    "    regressor = XGBRegressor()\n",
    "    param_grid = {\n",
    "        'tree_method': ['approx', 'hist'],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [3, 5, 7, 10, 12, 14],\n",
    "        'learning_rate': [0.2, 0.1, 0.01],\n",
    "        'subsample': [0.6, 0.7, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "        'enable_categorical': [True],\n",
    "    }\n",
    "\n",
    "    # define the GridSearchCV object with the parameter grid and the XGBRegressor model\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5)\n",
    "\n",
    "    # fit the GridSearchCV object on the training set\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # print the best hyperparameters and the corresponding mean cross-validated score\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best mean cross-validated score:\", grid_search.best_score_)\n",
    "\n",
    "    # retrain the model on the combined training and validation sets with the best hyperparameters\n",
    "    best_regressor = XGBRegressor(**grid_search.best_params_)\n",
    "    best_regressor.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # evaluate the final model performance on the test set\n",
    "    test_score = best_regressor.score(X_test, y_test)\n",
    "    print(\"Test score:\", test_score)\n",
    "\n",
    "    # regressor.fit(X_train, y_train)\n",
    "    # restWiseModelsXGB[storeId] = best_regressor\n",
    "\n",
    "    for storeId in allStoreIds:\n",
    "        X = restWiseDFs[storeId].loc[:, feature_cols]\n",
    "        y = restWiseDFs[storeId].prep_time.values.tolist()\n",
    "        predictions = best_regressor.predict(X)\n",
    "        restWiseDFs[storeId]['predicted_prep_time_central'] = predictions\n",
    "\n",
    "        a = getRMSE(y, predictions)\n",
    "        print(\"RMSE score overall for store central model (30 days) \" + storeId + \" :  \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f74d80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.062527Z",
     "start_time": "2023-03-10T10:34:07.062512Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rmse1 = ((trainingData.prep_time - trainingData.predicted_prep_time_central) ** 2).mean() ** .5\n",
    "rmse2 = ((trainingData.prep_time - trainingData.hour_wise_avg_kpt_of_the_day) ** 2).mean() ** .5\n",
    "# hour_wise_avg_kpt_of_the_day\n",
    "# rmse = ((df.prep_time - df.predicted_prep_time) ** 2).mean() ** .5\n",
    "#\n",
    "absError = (abs(trainingData.prep_time - trainingData.predicted_prep_time_central)).values.tolist()\n",
    "absError2 = (abs(trainingData.prep_time - trainingData.hour_wise_avg_kpt_of_the_day)).values.tolist()\n",
    "meanAbsError = statistics.mean(absError)\n",
    "medianAbsError = statistics.median(absError)\n",
    "\n",
    "meanAbsError2 = statistics.mean(absError2)\n",
    "medianAbsError2 = statistics.median(absError2)\n",
    "# stdAbsError = statistics.stdev(absError)\n",
    "#\n",
    "# error = (df.prep_time - df.predicted_prep_time).values.tolist()\n",
    "# meanError = statistics.mean(error)\n",
    "# medianError = statistics.median(error)\n",
    "# stdError = statistics.stdev(error)\n",
    "#\n",
    "# accuracy = (((df.prep_time - df.predicted_prep_time))/(7*60+df.prep_time)).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f74bd49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.063612Z",
     "start_time": "2023-03-10T10:34:07.063599Z"
    }
   },
   "outputs": [],
   "source": [
    "rmse1, rmse2, meanAbsError, meanAbsError2, medianAbsError, medianAbsError21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4d378c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.064747Z",
     "start_time": "2023-03-10T10:34:07.064735Z"
    }
   },
   "outputs": [],
   "source": [
    "if isCentralModel:\n",
    "    overallDF = pd.DataFrame()\n",
    "    for storeId in allStoreIds:\n",
    "        overallDF = pd.concat([overallDF, restWiseDFs[storeId]], ignore_index=True)\n",
    "    firstTime = datetime(2022, 7, 1)\n",
    "    lastTime = datetime(2022, 7, 21)\n",
    "    trainingData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "    X_train = trainingData.loc[:, feature_cols]\n",
    "    y_train = trainingData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 24)\n",
    "    lastTime = datetime(2022, 7, 22)\n",
    "    validationData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_train_val = validationData.loc[:, feature_cols]\n",
    "    y_train_val = validationData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 25)\n",
    "    lastTime = datetime(2022, 7, 31)\n",
    "    testData = overallDF.loc[(overallDF['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (overallDF['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_test = testData.loc[:, feature_cols]\n",
    "    y_test = testData.prep_time.values.tolist()\n",
    "\n",
    "\n",
    "    regressor = XGBRegressor()\n",
    "    param_grid = {\n",
    "        'tree_method': ['approx', 'hist'],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 7, 10, 13],\n",
    "        'learning_rate': [0.2, 0.1, 0.01],\n",
    "        'subsample': [0.6, 0.7, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "        'enable_categorical': [True],\n",
    "    }\n",
    "\n",
    "    # define the GridSearchCV object with the parameter grid and the XGBRegressor model\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5)\n",
    "\n",
    "    # fit the GridSearchCV object on the training set\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # print the best hyperparameters and the corresponding mean cross-validated score\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best mean cross-validated score:\", grid_search.best_score_)\n",
    "\n",
    "    # retrain the model on the combined training and validation sets with the best hyperparameters\n",
    "    best_regressor = XGBRegressor(**grid_search.best_params_)\n",
    "    best_regressor.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # evaluate the final model performance on the test set\n",
    "    test_score = best_regressor.score(X_test, y_test)\n",
    "    print(\"Test score:\", test_score)\n",
    "\n",
    "    # regressor.fit(X_train, y_train)\n",
    "    # restWiseModelsXGB[storeId] = best_regressor\n",
    "\n",
    "    for storeId in allStoreIds:\n",
    "        X = restWiseDFs[storeId].loc[:, feature_cols]\n",
    "        y = restWiseDFs[storeId].prep_time.values.tolist()\n",
    "        predictions = best_regressor.predict(X)\n",
    "        restWiseDFs[storeId]['predicted_prep_time_central'] = predictions\n",
    "\n",
    "        a = getRMSE(y, predictions)\n",
    "        print(\"RMSE score overall for store central model (30 days) \"+storeId+\" :  \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4f659c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96185470",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.066074Z",
     "start_time": "2023-03-10T10:34:07.066060Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "rmse1 = ((testingData.prep_time - testingData.predicted_prep_time_central) ** 2).mean() ** .5\n",
    "rmse2 = ((testingData.prep_time - testingData.hour_wise_avg_kpt_of_the_day) ** 2).mean() ** .5\n",
    "# hour_wise_avg_kpt_of_the_day\n",
    "# rmse = ((df.prep_time - df.predicted_prep_time) ** 2).mean() ** .5\n",
    "#\n",
    "absError = (abs(trainingData.prep_time - trainingData.predicted_prep_time_central)).values.tolist()\n",
    "absError2 = (abs(trainingData.prep_time - trainingData.hour_wise_avg_kpt_of_the_day)).values.tolist()\n",
    "meanAbsError = statistics.mean(absError)\n",
    "medianAbsError = statistics.median(absError)\n",
    "\n",
    "meanAbsError2 = statistics.mean(absError2)\n",
    "medianAbsError2 = statistics.median(absError2)\n",
    "# stdAbsError = statistics.stdev(absError)\n",
    "#\n",
    "# error = (df.prep_time - df.predicted_prep_time).values.tolist()\n",
    "# meanError = statistics.mean(error)\n",
    "# medianError = statistics.median(error)\n",
    "# stdError = statistics.stdev(error)\n",
    "#\n",
    "# accuracy = (((df.prep_time - df.predicted_prep_time))/(7*60+df.prep_time)).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335de2ba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.067068Z",
     "start_time": "2023-03-10T10:34:07.067055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Time Consuming (training on first 14 days of July)\n",
    "restWiseModelsXGB = {}\n",
    "\n",
    "for storeId in allStoreIds:\n",
    "    firstTime = datetime(2022, 7, 1)\n",
    "    lastTime = datetime(2022, 7, 14)\n",
    "    trainingData = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (restWiseDFs[storeId]['Kitchen_Display_Time'] <= lastTime)]\n",
    "    \n",
    "    X_train = trainingData.loc[:, feature_cols]\n",
    "    y_train = trainingData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 15)\n",
    "    lastTime = datetime(2022, 7, 21)\n",
    "    validationData = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (restWiseDFs[storeId]['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_train_val = validationData.loc[:, feature_cols]\n",
    "    y_train_val = validationData.prep_time.values.tolist()\n",
    "\n",
    "    firstTime = datetime(2022, 7, 22)\n",
    "    lastTime = datetime(2022, 7, 31)\n",
    "    testData = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (restWiseDFs[storeId]['Kitchen_Display_Time'] <= lastTime)]\n",
    "\n",
    "    X_test = testData.loc[:, feature_cols]\n",
    "    y_test = testData.prep_time.values.tolist()\n",
    "\n",
    "\n",
    "    regressor = XGBRegressor()\n",
    "    # define the parameter grid to search\n",
    "    param_grid = {\n",
    "        'tree_method': ['approx', 'hist'],\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [5, 7, 10, 13],\n",
    "        'learning_rate': [0.1, 0.01, 0.001],\n",
    "        'subsample': [0.6, 0.7, 0.8],\n",
    "        'colsample_bytree': [0.6, 0.7, 0.8],\n",
    "        'enable_categorical': [True],\n",
    "    }\n",
    "\n",
    "    # define the GridSearchCV object with the parameter grid and the XGBRegressor model\n",
    "    grid_search = GridSearchCV(estimator=regressor, param_grid=param_grid, cv=5)\n",
    "\n",
    "    # fit the GridSearchCV object on the training set\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # print the best hyperparameters and the corresponding mean cross-validated score\n",
    "    print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "    print(\"Best mean cross-validated score:\", grid_search.best_score_)\n",
    "\n",
    "    # retrain the model on the combined training and validation sets with the best hyperparameters\n",
    "    best_regressor = XGBRegressor(**grid_search.best_params_)\n",
    "    best_regressor.fit(X_train_val, y_train_val)\n",
    "\n",
    "    # evaluate the final model performance on the test set\n",
    "    test_score = best_regressor.score(X_test, y_test)\n",
    "    print(\"Test score:\", test_score)\n",
    "\n",
    "    # regressor.fit(X_train, y_train)\n",
    "    restWiseModelsXGB[storeId] = best_regressor\n",
    "    \n",
    "    \n",
    "    X = restWiseDFs[storeId].loc[:, feature_cols]\n",
    "    y = restWiseDFs[storeId].prep_time.values.tolist()\n",
    "    predictions = best_regressor.predict(X)\n",
    "    restWiseDFs[storeId]['predicted_prep_time'] = predictions\n",
    "    \n",
    "    a = getRMSE(y, predictions)\n",
    "    print(\"RMSE score overall for store (30 days) \"+storeId+\" :  \", a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8011b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.068568Z",
     "start_time": "2023-03-10T10:34:07.068556Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(restWiseDFs, f'restWiseDFsWithPredictions{city}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c659c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.069460Z",
     "start_time": "2023-03-10T10:34:07.069447Z"
    }
   },
   "outputs": [],
   "source": [
    "save_object(restWiseModelsXGB, f'restWiseModels{city}.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1417dc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8d7565",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.070578Z",
     "start_time": "2023-03-10T10:34:07.070566Z"
    }
   },
   "outputs": [],
   "source": [
    "def getPredictionHyperparameters(startDay, endDay): # both are included\n",
    "    df = pd.DataFrame()\n",
    "    firstTime = datetime(2022, 7, startDay)\n",
    "    lastTime = datetime(2022, 7, endDay) + timedelta(days=1)\n",
    "    for storeId in allStoreIds:\n",
    "        df2 = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (restWiseDFs[storeId]['Kitchen_Display_Time'] < lastTime) & \\\n",
    "                                       (restWiseDFs[storeId]['prep_time'] != timedelta(0))]\n",
    "        df = pd.concat([df, df2], ignore_index = True)\n",
    "    \n",
    "    rmse = ((df.prep_time - df.predicted_prep_time) ** 2).mean() ** .5\n",
    "    \n",
    "    absError = (abs(df.prep_time - df.predicted_prep_time)).values.tolist()\n",
    "    meanAbsError = statistics.mean(absError)\n",
    "    medianAbsError = statistics.median(absError)\n",
    "    stdAbsError = statistics.stdev(absError)\n",
    "    \n",
    "    error = (df.prep_time - df.predicted_prep_time).values.tolist()\n",
    "    meanError = statistics.mean(error)\n",
    "    medianError = statistics.median(error)\n",
    "    stdError = statistics.stdev(error)\n",
    "    \n",
    "    accuracy = (((df.prep_time - df.predicted_prep_time))/(7*60+df.prep_time)).values.tolist()\n",
    "    for i in range(0, len(accuracy)):\n",
    "        if accuracy[i] < 0:\n",
    "            accuracy[i] = -1*accuracy[i]\n",
    "        accuracy[i] = 1-accuracy[i]\n",
    "    meanAccuracy = statistics.mean(accuracy)\n",
    "    if not(meanAccuracy > 0 and meanAccuracy < 1):\n",
    "        print(\"Mean accuracy is zero: \")\n",
    "        print(meanAccuracy)\n",
    "    medianAccuracy = statistics.median(accuracy)\n",
    "    stdAccuracy = statistics.stdev(accuracy)\n",
    "    return rmse, (meanAbsError, medianAbsError, stdAbsError), (meanError, medianError, stdError), (meanAccuracy, medianAccuracy, stdAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e1f424",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.072282Z",
     "start_time": "2023-03-10T10:34:07.072267Z"
    }
   },
   "outputs": [],
   "source": [
    "rmseList = []\n",
    "meanAbsErrorList = []\n",
    "medianAbsErrorList = []\n",
    "stdAbsErrorList = []\n",
    "meanErrorList = []\n",
    "medianErrorList = []\n",
    "stdErrorList = []\n",
    "meanAccuracyList = []\n",
    "medianAccuracyList = []\n",
    "stdAccuracyList = []\n",
    "\n",
    "x = [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "for i in x:\n",
    "    (rmse, (meanAbsError, medianAbsError, stdAbsError), \n",
    "    (meanError, medianError, stdError), \n",
    "    (meanAccuracy, medianAccuracy, stdAccuracy)) = getPredictionHyperparameters(i,i)\n",
    "    rmseList.append(rmse)\n",
    "    meanAbsErrorList.append(meanAbsError)\n",
    "    medianAbsErrorList.append(medianAbsError)\n",
    "    stdAbsErrorList.append(stdAbsError)\n",
    "    meanErrorList.append(meanError)\n",
    "    medianErrorList.append(medianError)\n",
    "    stdErrorList.append(stdError)\n",
    "    meanAccuracyList.append(meanAccuracy)\n",
    "    medianAccuracyList.append(medianAccuracy)\n",
    "    stdAccuracyList.append(stdAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da6820d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.073099Z",
     "start_time": "2023-03-10T10:34:07.073088Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.bar(x, rmseList)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"RMSE value on the respective day\")\n",
    "plt.title(\"Model predictions with days\")\n",
    "plt.savefig(f'{city}_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7275d7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.074246Z",
     "start_time": "2023-03-10T10:34:07.074233Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.bar(x, medianAbsErrorList)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Absolute Value of error (median) on the respective day\")\n",
    "plt.title(\"Model predictions with days\")\n",
    "plt.savefig(f'{city}_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d98e9e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.075083Z",
     "start_time": "2023-03-10T10:34:07.075071Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.errorbar(x, meanErrorList, stdErrorList)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"error (mean, std dev of the day) on the respective day\")\n",
    "plt.title(\"Model predictions with days\")\n",
    "plt.savefig(f'{city}_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4180da9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.076123Z",
     "start_time": "2023-03-10T10:34:07.076112Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.bar(x, medianErrorList)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"error (median) on the respective day\")\n",
    "plt.title(\"Model predictions with days\")\n",
    "plt.savefig(f'{city}_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ca9374",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.077034Z",
     "start_time": "2023-03-10T10:34:07.077023Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.errorbar(x, meanAccuracyList, stdAccuracyList)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Accuracy (mean, std dev of the day) on the respective day\")\n",
    "plt.title(\"Model predictions with days\")\n",
    "plt.savefig(f'{city}_6.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a29c30",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.078001Z",
     "start_time": "2023-03-10T10:34:07.077989Z"
    }
   },
   "outputs": [],
   "source": [
    "overallDf = pd.DataFrame()\n",
    "for storeId in allStoreIds:\n",
    "        overallDf = pd.concat([overallDf, restWiseDFs[storeId]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc79ae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.078987Z",
     "start_time": "2023-03-10T10:34:07.078976Z"
    }
   },
   "outputs": [],
   "source": [
    "a = overallDf.loc[(overallDf['Oven_Time'] - overallDf['Kitchen_Display_Time'] < timedelta(seconds=1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9bc55e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.079895Z",
     "start_time": "2023-03-10T10:34:07.079883Z"
    }
   },
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdf4bd8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.080868Z",
     "start_time": "2023-03-10T10:34:07.080856Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.ylim(0.8, 1)\n",
    "plt.bar(x, medianAccuracyList)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Accuracy (median) on the respective day\")\n",
    "plt.title(\"Model predictions with days\")\n",
    "plt.savefig(f'{city}_7.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bfe46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.081875Z",
     "start_time": "2023-03-10T10:34:07.081863Z"
    }
   },
   "outputs": [],
   "source": [
    "# baseline approach\n",
    "# Hourwise avg \n",
    "\n",
    "weekdayHourWiseAvg = {}\n",
    "weekendHourWiseAvg = {}\n",
    "for store in allStoreIds:\n",
    "    weekdayHourWiseAvg[store] = {}\n",
    "    weekendHourWiseAvg[store] = {}\n",
    "for i in range(1, 15):\n",
    "    dt = datetime(2022, 7, i)\n",
    "    for storeId in allStoreIds:\n",
    "        df = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= dt) & \\\n",
    "          (restWiseDFs[storeId]['Kitchen_Display_Time'] < dt+timedelta(days=1))]\n",
    "        for index, item in df.iterrows():\n",
    "            ts = getTimeslot(item['Kitchen_Display_Time'])\n",
    "            if(dayOfTheWeek(item['Kitchen_Display_Time']) >= 5):\n",
    "                if ts not in weekendHourWiseAvg[storeId]:\n",
    "                    weekendHourWiseAvg[storeId][ts] = {'val': 0, 'cnt': 0}\n",
    "                weekendHourWiseAvg[storeId][ts]['val'] += item['prep_time']\n",
    "                weekendHourWiseAvg[storeId][ts]['cnt'] += 1\n",
    "            else:\n",
    "                if ts not in weekdayHourWiseAvg[storeId]:\n",
    "                    weekdayHourWiseAvg[storeId][ts] = {'val': 0, 'cnt': 0}\n",
    "                weekdayHourWiseAvg[storeId][ts]['val'] += item['prep_time']\n",
    "                weekdayHourWiseAvg[storeId][ts]['cnt'] += 1\n",
    "\n",
    "for storeId in allStoreIds:\n",
    "    for ts in weekdayHourWiseAvg[storeId].keys():\n",
    "        weekdayHourWiseAvg[storeId][ts]['val'] = weekdayHourWiseAvg[storeId][ts]['val']/weekdayHourWiseAvg[storeId][ts]['cnt']\n",
    "    for ts in weekendHourWiseAvg[storeId].keys():\n",
    "        weekendHourWiseAvg[storeId][ts]['val'] = weekendHourWiseAvg[storeId][ts]['val']/weekendHourWiseAvg[storeId][ts]['cnt']\n",
    "        \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba4d96",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.084064Z",
     "start_time": "2023-03-10T10:34:07.084052Z"
    }
   },
   "outputs": [],
   "source": [
    "overallDF = pd.DataFrame()\n",
    "for storeId in allStoreIds:\n",
    "    overallDF = pd.concat([overallDF, restWiseDFs[storeId]], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f27b15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.085006Z",
     "start_time": "2023-03-10T10:34:07.084995Z"
    }
   },
   "outputs": [],
   "source": [
    "avgs = []\n",
    "for index, item in overallDF.iterrows():\n",
    "    ts = getTimeslot(item['Kitchen_Display_Time'])\n",
    "    storeId = item['Location_Code']\n",
    "    if(dayOfTheWeek(item['Kitchen_Display_Time']) >= 5):\n",
    "        if(ts not in weekendHourWiseAvg[storeId]):\n",
    "            avgs.append(0)\n",
    "        else:\n",
    "            avgs.append(weekendHourWiseAvg[storeId][ts]['val'] )\n",
    "    else:\n",
    "        if(ts not in weekdayHourWiseAvg[storeId]):\n",
    "            avgs.append(0)\n",
    "        else:\n",
    "            avgs.append(weekdayHourWiseAvg[storeId][ts]['val'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1550749",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.086006Z",
     "start_time": "2023-03-10T10:34:07.085995Z"
    }
   },
   "outputs": [],
   "source": [
    "overallDF['hourwise_avg'] = avgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef84e7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.087195Z",
     "start_time": "2023-03-10T10:34:07.087181Z"
    }
   },
   "outputs": [],
   "source": [
    "restWiseDFs = {}\n",
    "for storeId in allStoreIds:\n",
    "    restWiseDFs[storeId] = overallDF.loc[overallDF['Location_Code'] == storeId]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad81ec9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.088267Z",
     "start_time": "2023-03-10T10:34:07.088255Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBaselineHyperparameters(startDay, endDay): # both are included\n",
    "    df = pd.DataFrame()\n",
    "    firstTime = datetime(2022, 7, startDay)\n",
    "    lastTime = datetime(2022, 7, endDay) + timedelta(days=1)\n",
    "    for storeId in allStoreIds:\n",
    "        df2 = restWiseDFs[storeId].loc[(restWiseDFs[storeId]['Kitchen_Display_Time'] >= firstTime) & \\\n",
    "          (restWiseDFs[storeId]['Kitchen_Display_Time'] < lastTime)]\n",
    "        df = pd.concat([df, df2], ignore_index = True)\n",
    "    \n",
    "    rmse = ((df.prep_time - df.hourwise_avg) ** 2).mean() ** .5\n",
    "    \n",
    "    absError = (abs(df.prep_time - df.hourwise_avg)).values.tolist()\n",
    "    meanAbsError = statistics.mean(absError)\n",
    "    medianAbsError = statistics.median(absError)\n",
    "    stdAbsError = statistics.stdev(absError)\n",
    "    \n",
    "    error = (df.prep_time - df.hourwise_avg).values.tolist()\n",
    "    meanError = statistics.mean(error)\n",
    "    medianError = statistics.median(error)\n",
    "    stdError = statistics.stdev(error)\n",
    "    \n",
    "    accuracy = ((df.prep_time - abs(df.prep_time - df.hourwise_avg))/df.prep_time).values.tolist()\n",
    "    meanAccuracy = statistics.mean(accuracy)\n",
    "    medianAccuracy = statistics.median(accuracy)\n",
    "    stdAccuracy = statistics.stdev(accuracy)\n",
    "    return rmse, (meanAbsError, medianAbsError, stdAbsError), (meanError, medianError, stdError), (meanAccuracy, medianAccuracy, stdAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327b6871",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.089529Z",
     "start_time": "2023-03-10T10:34:07.089517Z"
    }
   },
   "outputs": [],
   "source": [
    "rmseListBL = []\n",
    "meanAbsErrorListBL = []\n",
    "medianAbsErrorListBL = []\n",
    "stdAbsErrorListBL = []\n",
    "meanErrorListBL = []\n",
    "medianErrorListBL = []\n",
    "stdErrorListBL = []\n",
    "meanAccuracyListBL = []\n",
    "medianAccuracyListBL = []\n",
    "stdAccuracyListBL = []\n",
    "\n",
    "x = [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "\n",
    "for i in x:\n",
    "    (rmse, (meanAbsError, medianAbsError, stdAbsError), \n",
    "    (meanError, medianError, stdError), \n",
    "    (meanAccuracy, medianAccuracy, stdAccuracy)) = getBaselineHyperparameters(i,i)\n",
    "    rmseListBL.append(rmse)\n",
    "    meanAbsErrorListBL.append(meanAbsError)\n",
    "    medianAbsErrorListBL.append(medianAbsError)\n",
    "    stdAbsErrorListBL.append(stdAbsError)\n",
    "    meanErrorListBL.append(meanError)\n",
    "    medianErrorListBL.append(medianError)\n",
    "    stdErrorListBL.append(stdError)\n",
    "    meanAccuracyListBL.append(meanAccuracy)\n",
    "    medianAccuracyListBL.append(medianAccuracy)\n",
    "    stdAccuracyListBL.append(stdAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c1fd68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.090382Z",
     "start_time": "2023-03-10T10:34:07.090371Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.bar(x, rmseListBL)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"RMSE value on the respective day\")\n",
    "plt.title(\"Baseline prediction\")\n",
    "plt.savefig(f'BL_{city}_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954fa3a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.091417Z",
     "start_time": "2023-03-10T10:34:07.091404Z"
    }
   },
   "outputs": [],
   "source": [
    "rmseListBL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d27811",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf96bec6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.092208Z",
     "start_time": "2023-03-10T10:34:07.092196Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.bar(x, medianAbsErrorListBL)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Absolute Value of error (median) on the respective day\")\n",
    "plt.title(\"Baseline Prediction\")\n",
    "plt.savefig(f'BL_{city}_3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc67186",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.093120Z",
     "start_time": "2023-03-10T10:34:07.093108Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.errorbar(x, meanErrorListBL, stdErrorListBL)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"error (mean, std dev of the day) on the respective day\")\n",
    "plt.title(\"Baseline Prediction\")\n",
    "plt.savefig(f'BL_{city}_4.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78dcc1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.094114Z",
     "start_time": "2023-03-10T10:34:07.094101Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.bar(x, medianErrorListBL)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"error (median) on the respective day\")\n",
    "plt.title(\"Baseline Prediction\")\n",
    "plt.savefig(f'BL_{city}_5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bed860",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.095491Z",
     "start_time": "2023-03-10T10:34:07.095478Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.errorbar(x, meanAccuracyListBL, stdAccuracyListBL)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Accuracy (mean, std dev of the day) on the respective day\")\n",
    "plt.title(\"Baseline Prediction\")\n",
    "plt.savefig(f'BL_{city}_6.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d9b44a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.096568Z",
     "start_time": "2023-03-10T10:34:07.096556Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot for 15, 20, 25, 30 july \n",
    "plt.ylim(0.7, 1)\n",
    "plt.bar(x, medianAccuracyListBL)\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Accuracy (median) on the respective day\")\n",
    "plt.title(\"Baseline Prediction\")\n",
    "plt.savefig(f'BL_{city}_7.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77100fb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cee0a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.097520Z",
     "start_time": "2023-03-10T10:34:07.097508Z"
    }
   },
   "outputs": [],
   "source": [
    "(rmseTr, (meanAbsErrorTr, medianAbsErrorTr, stdAbsErrorTr), \n",
    "    (meanErrorTr, medianErrorTr, stdErrorTr), \n",
    "    (meanAccuracyTr, medianAccuracyTr, stdAccuracyTr)) = getPredictionHyperparameters(1, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c174c632",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.098377Z",
     "start_time": "2023-03-10T10:34:07.098360Z"
    }
   },
   "outputs": [],
   "source": [
    "(rmseTe, (meanAbsErrorTe, medianAbsErrorTe, stdAbsErrorTe), \n",
    "    (meanErrorTe, medianErrorTe, stdErrorTe), \n",
    "    (meanAccuracyTe, medianAccuracyTe, stdAccuracyTe)) = getPredictionHyperparameters(15, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47b7600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.099261Z",
     "start_time": "2023-03-10T10:34:07.099250Z"
    }
   },
   "outputs": [],
   "source": [
    "(rmseTr, (meanAbsErrorTr, medianAbsErrorTr, stdAbsErrorTr), \n",
    "    (meanErrorTr, medianErrorTr, stdErrorTr), \n",
    "    (meanAccuracyTr, medianAccuracyTr, stdAccuracyTr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37efa14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.100203Z",
     "start_time": "2023-03-10T10:34:07.100192Z"
    }
   },
   "outputs": [],
   "source": [
    "(rmseTe, (meanAbsErrorTe, medianAbsErrorTe, stdAbsErrorTe), \n",
    "    (meanErrorTe, medianErrorTe, stdErrorTe), \n",
    "    (meanAccuracyTe, medianAccuracyTe, stdAccuracyTe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2d9cc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.101078Z",
     "start_time": "2023-03-10T10:34:07.101066Z"
    }
   },
   "outputs": [],
   "source": [
    "x = [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "plt.plot(x, rmseList, label=\"xgboost model\")\n",
    "plt.plot(x, rmseListBL, label='baseline')\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"RMSE Comparison on the respective day\")\n",
    "plt.title(\"Model vs Baseline in RMSE values\")\n",
    "plt.legend()\n",
    "plt.savefig(f'BL_{city}_7.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a275958a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.102648Z",
     "start_time": "2023-03-10T10:34:07.102637Z"
    }
   },
   "outputs": [],
   "source": [
    "x = [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n",
    "plt.plot(x, medianAbsErrorList, label=\"xgboost model\")\n",
    "plt.plot(x, medianAbsErrorListBL, label='baseline')\n",
    "plt.xticks(x)\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Median Abs Error Comparison on the respective day\")\n",
    "plt.title(\"Model vs Baseline in Median Abs Error\")\n",
    "plt.legend()\n",
    "plt.savefig(f'BL_{city}_8.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a62a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.103991Z",
     "start_time": "2023-03-10T10:34:07.103980Z"
    }
   },
   "outputs": [],
   "source": [
    "def getErrorSlot(error):\n",
    "    return (error//5)*5\n",
    "\n",
    "cnt = {}\n",
    "for index, item in overallDF.iterrows():\n",
    "    error = (item['prep_time'] - item['predicted_prep_time'])/60\n",
    "    lts = getErrorSlot(error)\n",
    "    if(lts not in cnt):\n",
    "        cnt[lts]=1\n",
    "    else:\n",
    "        cnt[lts]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e1997ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.105481Z",
     "start_time": "2023-03-10T10:34:07.105471Z"
    }
   },
   "outputs": [],
   "source": [
    "ranges = sorted(cnt.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed57caa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.107212Z",
     "start_time": "2023-03-10T10:34:07.107200Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt[-10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbdd43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.108021Z",
     "start_time": "2023-03-10T10:34:07.108009Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt[-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb5d0cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.109072Z",
     "start_time": "2023-03-10T10:34:07.109060Z"
    }
   },
   "outputs": [],
   "source": [
    "cnt[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1d7ce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-10T10:34:07.110063Z",
     "start_time": "2023-03-10T10:34:07.110052Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eade10b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28e25c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24840d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "643e39c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37998c04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2987534",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b71d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e163cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69030144",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aea9f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6969b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaf46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07375c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af35e731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a30a4c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f8bebb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068d3e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d1850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10369e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
