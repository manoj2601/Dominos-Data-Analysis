{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2f4650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import sklearn\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d35558d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading data from bhopal\n",
    "df = pd.read_excel('./LevelOneCleaning/Bhopal.xlsx', sheet_name='Orders')\n",
    "l = df.to_dict('records')\n",
    "orders = []\n",
    "for dic in l:\n",
    "\torders.append(dic)\n",
    "ordersBhopal = []\n",
    "for dic in l:\n",
    "    ordersBhopal.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6a7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading data from Mumbai\n",
    "df2 = pd.read_excel('./LevelOneCleaning/Mumbai.xlsx', sheet_name='Orders')\n",
    "l2 = df2.to_dict('records')\n",
    "for dic in l2:\n",
    "    orders.append(dic)\n",
    "    \n",
    "ordersMumbai = []\n",
    "for dic in l:\n",
    "    ordersMumbai.append(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2009f5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeaturesFromItems(oi):\n",
    "    res = json.loads(oi)\n",
    "    a = res['order_menu']\n",
    "    for y in a:\n",
    "        l1 = [y['menu_description'], y['quantity'], y['order_line_total'], y['menu_code']]\n",
    "        if(y['menu_code'][0:3] == 'BEV' or y['menu_code'][0:3] == 'DIP'):\n",
    "            continue\n",
    "        if y['menu_code'][0:3] in dic:\n",
    "            dic[y['menu_code'][0:3]] += int(y['quantity'])\n",
    "        else:\n",
    "            dic[y['menu_code'][0:3]] = int(y['quantity'])\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHotEncodingRestaurant(dp):\n",
    "    restaurants = ['dpi63827', 'dpi63919', 'dpi64196','dpi66154','dpi66221','dpi66313','dpi66373','dpi66449','dpi66576','dpi66653','dpi67072']\n",
    "    l = []\n",
    "    for i in range(0, len(restaurants)):\n",
    "        if(restaurants[i] == dp):\n",
    "            l.append(1)\n",
    "        else:\n",
    "            l.append(0)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69429a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getItemsFeatures(it):\n",
    "    itd = makeFeaturesFromItems(it)\n",
    "    item_types = ['BRD','CAK','DST','NVP','PIZ','SID','TAC','VGP']\n",
    "    l = []\n",
    "    for i in range(0, len(item_types)):\n",
    "        l.append(0)\n",
    "    for key in itd.keys():\n",
    "        for i in range(0, len(item_types)):\n",
    "            if(item_types[i] == key):\n",
    "                l[i] = itd[key]\n",
    "                break\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5dcdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_slots = 24\n",
    "def getTimeIndex(dt):\n",
    "\tcurrent = datetime.datetime(2011, 1, 1)\n",
    "\tt1 = current.time()\n",
    "\tt2 = dt.time()\n",
    "\tfor i in range(0, total_slots):\n",
    "\t\tcurrent = current + datetime.timedelta(minutes = 60)\n",
    "\t\tif(current.time() > t2):\n",
    "\t\t\treturn i\n",
    "\treturn total_slots-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defae7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getOneHotEncodingTimeSlot(ts):\n",
    "    l = []\n",
    "    for i in range(0, 24):\n",
    "        l.append(0)\n",
    "    l[ts] = 1\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017e620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preparation_time(order):\n",
    "\tdt1 = datetime.datetime.strptime(order['ORDER_MAKELINE_DATE_TIME'], \"%Y-%m-%d %H:%M:%S\")\n",
    "\tdt2 = datetime.datetime.strptime(order['KITCHEN_DISPLAY_TIME'], \"%Y-%m-%d %H:%M:%S\")\n",
    "\tdiff = dt1 - dt2\n",
    "\treturn diff.total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6bca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for Bhopal Model\n",
    "# \n",
    "threshold = 30 # minutes for preparation time (threshold)\n",
    "maxDifference = 1 # minute difference (abs) between predicted time and real time to assume prediction correct\n",
    "splitMethod = 'random' # random, weekdays, weekends, mix\n",
    "X_train, X_test, y_train, y_test = [], [], [], []\n",
    "X = []\n",
    "y = []\n",
    "for order in ordersBhopal:\n",
    "    features = []\n",
    "    features = getItemsFeatures(order['ORDER_ITEMS'])\n",
    "    features = features + getOneHotEncodingRestaurant(order['STORE_ID'])\n",
    "    features = features + getOneHotEncodingTimeSlot(getTimeIndex(datetime.datetime.strptime(order['ORDER_RECEIVED_DATE_TIME'], \"%Y-%m-%d %H:%M:%S\")))\n",
    "#     if(get_preparation_time(order) > (threshold-9)*60): #removing inputs \n",
    "#         continue\n",
    "    X.append(features)\n",
    "    y.append(540+get_preparation_time(order))\n",
    "    if((order['ORDER_DATE'] >='2021-12-20' and order['ORDER_DATE'] <= '2021-12-24') or (order['ORDER_DATE'] >='2021-12-27' and order['ORDER_DATE'] <= '2021-12-29')):\n",
    "        X_train.append(features)\n",
    "        y_train.append(540+get_preparation_time(order))\n",
    "    elif(order['ORDER_DATE'] =='2021-12-30'):\n",
    "        X_test.append(features)\n",
    "        y_test.append(540+get_preparation_time(order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0201b511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18309"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "if splitMethod == 'random':\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "06e59282",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(hidden_layer_sizes=(80, 30, 10), activation='relu', max_iter=1000, verbose=True, learning_rate='constant', learning_rate_init=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "3bc8449f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#activation: relu, logistic, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "002da624",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 8.94234618\n",
      "Iteration 2, loss = 6.23212646\n",
      "Iteration 3, loss = 5.99764360\n",
      "Iteration 4, loss = 5.88225634\n",
      "Iteration 5, loss = 5.82635889\n",
      "Iteration 6, loss = 5.79713412\n",
      "Iteration 7, loss = 5.78075823\n",
      "Iteration 8, loss = 5.77066400\n",
      "Iteration 9, loss = 5.76381215\n",
      "Iteration 10, loss = 5.75891112\n",
      "Iteration 11, loss = 5.75542445\n",
      "Iteration 12, loss = 5.75267255\n",
      "Iteration 13, loss = 5.75062544\n",
      "Iteration 14, loss = 5.74862906\n",
      "Iteration 15, loss = 5.74736932\n",
      "Iteration 16, loss = 5.74591542\n",
      "Iteration 17, loss = 5.74519347\n",
      "Iteration 18, loss = 5.74456708\n",
      "Iteration 19, loss = 5.74420422\n",
      "Iteration 20, loss = 5.74377744\n",
      "Iteration 21, loss = 5.74344878\n",
      "Iteration 22, loss = 5.74311662\n",
      "Iteration 23, loss = 5.74311713\n",
      "Iteration 24, loss = 5.74291607\n",
      "Iteration 25, loss = 5.74304818\n",
      "Iteration 26, loss = 5.74287426\n",
      "Iteration 27, loss = 5.74272567\n",
      "Iteration 28, loss = 5.74267729\n",
      "Iteration 29, loss = 5.74267284\n",
      "Iteration 30, loss = 5.74251606\n",
      "Iteration 31, loss = 5.74233710\n",
      "Iteration 32, loss = 5.74239922\n",
      "Iteration 33, loss = 5.74227255\n",
      "Iteration 34, loss = 5.74230139\n",
      "Iteration 35, loss = 5.74253920\n",
      "Iteration 36, loss = 5.74247971\n",
      "Iteration 37, loss = 5.74249480\n",
      "Iteration 38, loss = 5.74262377\n",
      "Iteration 39, loss = 5.74197987\n",
      "Iteration 40, loss = 5.74222757\n",
      "Iteration 41, loss = 5.74204727\n",
      "Iteration 42, loss = 5.74215418\n",
      "Iteration 43, loss = 5.74220653\n",
      "Iteration 44, loss = 5.74228935\n",
      "Iteration 45, loss = 5.74220974\n",
      "Iteration 46, loss = 5.74216293\n",
      "Iteration 47, loss = 5.74203483\n",
      "Iteration 48, loss = 5.74206318\n",
      "Iteration 49, loss = 5.74196565\n",
      "Iteration 50, loss = 5.74211790\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "5.741965652871755\n"
     ]
    }
   ],
   "source": [
    "mlp.fit(X_train, y_train)\n",
    "print(mlp.best_loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "38292f33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'softmax'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.out_activation_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f673c54c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = mlp.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6218cfa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3662"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ab069e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-6.86428495, -7.47516641, -7.1210821 , ..., -9.65384623,\n",
       "        -9.60329861, -9.60688109],\n",
       "       [-6.86428495, -7.47516641, -7.1210821 , ..., -9.65384623,\n",
       "        -9.60329861, -9.60688109],\n",
       "       [-6.86428495, -7.47516641, -7.1210821 , ..., -9.65384623,\n",
       "        -9.60329861, -9.60688109],\n",
       "       ...,\n",
       "       [-6.86428495, -7.47516641, -7.1210821 , ..., -9.65384623,\n",
       "        -9.60329861, -9.60688109],\n",
       "       [-6.86428495, -7.47516641, -7.1210821 , ..., -9.65384623,\n",
       "        -9.60329861, -9.60688109],\n",
       "       [-6.86428495, -7.47516641, -7.1210821 , ..., -9.65384623,\n",
       "        -9.60329861, -9.60688109]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.predict_log_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e868065c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "372.83643981706683"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_train, predictions)  \n",
    "rmse = math.sqrt(mse)  \n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7aaa1601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5608956854178044\n",
      "total :  3662\n",
      "correct:  1608\n"
     ]
    }
   ],
   "source": [
    "7cnt=0\n",
    "for x, y in zip(y_test, predictions):\n",
    "    if(abs(x-y) >= maxDifference*60):\n",
    "        cnt+=1\n",
    "#         print(x, y, x-y)\n",
    "accuracy = (len(y_test)-cnt)/len(y_test)\n",
    "\n",
    "print(\"Accuracy: \", accuracy)\n",
    "print('total : ', len(y_test))\n",
    "print(\"correct: \", cnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0792c01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab797e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "regressor = RandomForestRegressor()\n",
    "regressor.fit(X_train, y_train)\n",
    "predictions = regressor.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325642ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = sklearn.metrics.mean_squared_error(y_train, predictions)  \n",
    "rmse = math.sqrt(mse)  \n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86367044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRMSE(actual, predictions):\n",
    "    mse = sklearn.metrics.mean_squared_error(actual, predictions)\n",
    "    return math.sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a01c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ModelResults(X_train, X_test, y_train, y_test, model, isNormalizationRequired=True):\n",
    "    if(isNormalizationRequired):\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(X_train)\n",
    "\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "    if(model=='NN'):\n",
    "        hidden_layer_sizes=(80, 30, 10)\n",
    "        activation='relu'\n",
    "        print(\"Neural Network model\")\n",
    "        print(\"Hidden layers: \", hidden_layer_sizes)\n",
    "        print(\"Activation function: \", activation)\n",
    "        mlp = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation=activation, max_iter=1000, verbose=True, learning_rate='constant', learning_rate_init=0.01)\n",
    "        mlp.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = mlp.predict(X_train)\n",
    "        print(\"RMSE score on validation set: \", getRMSE(y_train, predictions))\n",
    "        \n",
    "        predictions = mlp.predict(X_test)\n",
    "        print(\"RMSE score on test set: \", getRMSE(y_test, predictions))\n",
    "        \n",
    "    elif(model=='RF'):\n",
    "        print(\"Random Forest Model\")\n",
    "        regressor = RandomForestRegressor()\n",
    "        regressor.fit(X_train, y_train)\n",
    "        \n",
    "        predictions = regressor.predict(X_train)\n",
    "        print(\"RMSE score on validation set: \", getRMSE(y_train, predictions))\n",
    "        \n",
    "        predictions = regressor.predict(X_test)\n",
    "        print(\"RMSE score on test set: \", getRMSE(y_test, predictions))\n",
    "    else:\n",
    "        print(\"Model not implemented yet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
